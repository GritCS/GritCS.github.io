<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","version":"8.6.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Suche...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="记录点滴成长">
<meta property="og:type" content="website">
<meta property="og:title" content="Think World">
<meta property="og:url" content="http://example.com/page/7/index.html">
<meta property="og:site_name" content="Think World">
<meta property="og:description" content="记录点滴成长">
<meta property="og:locale">
<meta property="article:author" content="Sherry Wang">
<meta property="article:tag" content="computer vision, DeepLearning ,MachineLearning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/7/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-Hans","comments":"","permalink":"","path":"page/7/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Think World</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Navigationsleiste an/ausschalten" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Think World</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">从个人成长角度来说，从经历中学点什么总是最重要的</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Inhaltsverzeichnis
        </li>
        <li class="sidebar-nav-overview">
          Übersicht
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sherry Wang"
      src="/images/aa.webp">
  <p class="site-author-name" itemprop="name">Sherry Wang</p>
  <div class="site-description" itemprop="description">记录点滴成长</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">72</span>
          <span class="site-state-item-name">Artikel</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">Kategorien</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">schlagwörter</span></a>
      </div>
  </nav>
</div>



          </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/25/%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/25/%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/" class="post-title-link" itemprop="url">合并与分割</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-08-25 00:06:15" itemprop="dateCreated datePublished" datetime="2020-08-25T00:06:15+08:00">2020-08-25</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-24 23:04:32" itemprop="dateModified" datetime="2020-08-24T23:04:32+08:00">2020-08-24</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="合并与分割"><a href="#合并与分割" class="headerlink" title="合并与分割"></a>合并与分割</h2><h3 id="1-cat"><a href="#1-cat" class="headerlink" title="1. cat"></a>1. cat</h3><p><img src="%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/2020-08-25_06-36.png" alt="2020-08-25_06-36"></p>
<p><img src="%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/2020-08-25_06-38.png" alt="2020-08-25_06-38"></p>
<p><img src="%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/2020-08-25_06-38_1.png" alt="2020-08-25_06-38_1"></p>
<h3 id="2-stack"><a href="#2-stack" class="headerlink" title="2. stack"></a>2. stack</h3><p><img src="%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/2020-08-25_06-35.png" alt="2020-08-25_06-35"></p>
<h3 id="cat-v-s-stack"><a href="#cat-v-s-stack" class="headerlink" title="cat v.s. stack"></a>cat v.s. stack</h3><p><img src="%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2/2020-08-25_07-04.png" alt="2020-08-25_07-04"></p>
<h3 id="3-split"><a href="#3-split" class="headerlink" title="3. split"></a>3. split</h3><h4 id="by-sub-len"><a href="#by-sub-len" class="headerlink" title="by sub-len"></a>by sub-len</h4><p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.chunk(sub_size ,dim =dd)	<span class="comment">#拆分成若干个size都为sub_size的tensor</span></span><br><span class="line"></span><br><span class="line">torch.chunk([sub.size1,sub_size2.....],dim=d) <span class="comment">#拆分成各分布为size1,size2...的tensor</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="4-chunk"><a href="#4-chunk" class="headerlink" title="4. chunk"></a>4. chunk</h3><h4 id="by-sub-num"><a href="#by-sub-num" class="headerlink" title="by sub-num"></a>by sub-num</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.chunk(sub_num ,dim =dd)</span><br></pre></td></tr></table></figure>



<p>汇总代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line">a1 = torch.randn(<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line">a2 = torch.randn(<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line">b = torch.randn(<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line">b2= torch.randn(<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line">b3 = torch.randn(<span class="number">32</span>,<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">c = torch.stack([a,b],dim=<span class="number">0</span>)</span><br><span class="line">d = torch.cat([a,b],dim=<span class="number">0</span>)</span><br><span class="line">d = torch.cat([a1,d],dim=<span class="number">0</span>)</span><br><span class="line">d = torch.cat([a2,d],dim=<span class="number">0</span>)</span><br><span class="line">d = torch.cat([b2,d],dim=<span class="number">0</span>)</span><br><span class="line">d = torch.cat([b3,d],dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(d.shape)</span><br><span class="line"></span><br><span class="line">n,m = d.split([<span class="number">2</span>*<span class="number">32</span>,<span class="number">4</span>*<span class="number">32</span>],dim=<span class="number">0</span>) <span class="comment">#指定每个sub-tensor的size,使用list表示，所有size的和必须等于拆分前的tensor的size</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(n.shape)</span><br><span class="line"><span class="built_in">print</span>(m.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nn,mm = d.split(<span class="number">3</span>*<span class="number">32</span>,dim=<span class="number">0</span>) <span class="comment">#如果所有长度都固定，就用一个数来表示每个sub-tensor的长度，sub-tensor的个数可以自动计算得到</span></span><br><span class="line"><span class="comment"># nn,mm = d.split(3,dim=0) #报错，如果每个sub-tensor第一维的size＝３，会返回64个sub-tensor</span></span><br><span class="line"><span class="built_in">print</span>(nn.shape)</span><br><span class="line"><span class="built_in">print</span>(mm.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nnn ,mmm = d.chunk(<span class="number">2</span>,dim=<span class="number">0</span>)<span class="comment">#拆分成两个tensor,每个tensor的长度相同为３*32</span></span><br><span class="line"><span class="built_in">print</span>(nnn.shape)</span><br><span class="line"><span class="built_in">print</span>(mmm.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/24/Broadcasting/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/24/Broadcasting/" class="post-title-link" itemprop="url">Broadcasting</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>
      

      <time title="Erstellt: 2020-08-24 23:43:31 / Geändert am: 16:05:46" itemprop="dateCreated datePublished" datetime="2020-08-24T23:43:31+08:00">2020-08-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="1-Broadcasting的基本准则"><a href="#1-Broadcasting的基本准则" class="headerlink" title="1.Broadcasting的基本准则"></a>1.Broadcasting的基本准则</h3><p><img src="Broadcasting/2020-08-25_00-03.png" alt="2020-08-25_00-03"></p>
<p>例子</p>
<p><img src="Broadcasting/2020-08-24_23-52.png" alt="2020-08-24_23-52"></p>
<h3 id="2-Broadcasting引入的背景"><a href="#2-Broadcasting引入的背景" class="headerlink" title="2.Broadcasting引入的背景"></a>2.Broadcasting引入的背景</h3><pre><code>1. 实际计算需求：可以允许不同shape(但又满足某种标准)的tensor可以进行计算
 2. 同时这种原则满足数学上的运算，又无需手动操作，又不会消耗很多的内存（对比repeat)
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/24/%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/24/%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/" class="post-title-link" itemprop="url">维度转换</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>
      

      <time title="Erstellt: 2020-08-24 16:42:48 / Geändert am: 12:33:24" itemprop="dateCreated datePublished" datetime="2020-08-24T16:42:48+08:00">2020-08-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h2><p><strong>数据没有被改变，改变的只有数据的理解方式</strong></p>
<h3 id="1-view-reshape"><a href="#1-view-reshape" class="headerlink" title="1. view / reshape"></a>1. view / reshape</h3><p>1.view reshape ,两个方法的用法完全相同<br>要求转换前后tensor的numel()相同即可，prod(a.size()) ==prod(b.size())</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a = torch.randn(<span class="number">4</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br><span class="line"><span class="comment">#把每张照片打成一维数据,这个常做为－卷积网络的输入</span></span><br><span class="line">b = a.view(<span class="number">4</span>,<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="comment">#把只是关注照片中每行的特点</span></span><br><span class="line">c = a.view(<span class="number">4</span>*<span class="number">1</span>*<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#不关心像素点是来自哪里，只是关注图片中不同像素点的不同</span></span><br><span class="line">d = a.view(<span class="number">4</span>*<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="built_in">print</span>(d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据的存储／维度顺序非常重要，但是这里view 和reshape函数在转换时把这一信息丢掉了，无额外记录之前的形状，无法恢复</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">torch.Size([4, 1, 28, 28])</span></span><br><span class="line"><span class="string">torch.Size([4, 784])</span></span><br><span class="line"><span class="string">torch.Size([112, 28])</span></span><br><span class="line"><span class="string">torch.Size([4, 28, 28])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h3 id="2-squeeze-v-s-unsqueeze-维度"><a href="#2-squeeze-v-s-unsqueeze-维度" class="headerlink" title="2.squeeze v.s. unsqueeze-维度"></a>2.squeeze v.s. unsqueeze-维度</h3><h4 id="2-1-unsqueeze"><a href="#2-1-unsqueeze" class="headerlink" title="2.1 unsqueeze()"></a>2.1 unsqueeze()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#unsqueeze( input , dim ) -&gt;Tensor</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#####参数说明：</span></span><br><span class="line"><span class="comment">#input (Tensor) – the input tensor.</span></span><br><span class="line"><span class="comment"># dim (int) – the index at which to insert the singleton dimension,dim的取值范围[- input.dim() -1 , input.dim()+1 ]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果dim为负数，则　dim = dim + input.dim()+1 将其转换成正数</span></span><br><span class="line"><span class="comment">#如果dim为整数，则　新增的维度添加到　dim的前面</span></span><br><span class="line"><span class="comment">#维度上的元素个数只有一个，所以数据规模没有改变，改变的只是数据的含义</span></span><br></pre></td></tr></table></figure>

<p><strong>图示</strong></p>
<p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/1.jpg" alt="1"></p>
<p>可以看出来维度变换之后，数据的理解方式不同，要好好体会</p>
<p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/2020-08-24_19-08.png" alt="2020-08-24_19-08"></p>
<p><strong>数据处理的实例应用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">b = torch.rand(<span class="number">32</span>)</span><br><span class="line">f = torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">14</span>,<span class="number">14</span>)</span><br><span class="line">b = b.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="comment">#方便之后 f+b的计算。b 即bias，相当于给每个channel上的所有像素增加一个偏置</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output : torch.Size([1, 32, 1, 1])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">##常用的：　就是如果向后面插就使用　unsqueeze(-1)多次插入，就多次写</span></span><br><span class="line"><span class="comment">#向开头插入就，直接调用 unsqueeze(0)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-2-squeeze"><a href="#2-2-squeeze" class="headerlink" title="2.2 squeeze"></a>2.2 squeeze</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#torch.squeeze(input , dim =None ,Out = None) -&gt;tensor</span></span><br><span class="line"><span class="comment">#当不传参数时，会将input所有元素只有一个的维度给去掉</span></span><br><span class="line"><span class="comment">#传参数dim，在指定维度上且维度只有一个元素时，将挤压掉该维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#b.shape = torch.Size([1,32,1,1])</span></span><br><span class="line"><span class="built_in">print</span>(b.squeeze(-<span class="number">1</span>).shape)</span><br><span class="line"><span class="built_in">print</span>(b.squeeze(<span class="number">1</span>).shape) <span class="comment">#无效</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([1, 32, 1])</span></span><br><span class="line"><span class="string">torch.Size([1, 32, 1, 1])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="3-Expand-repeat-行"><a href="#3-Expand-repeat-行" class="headerlink" title="3.Expand /repeat-行"></a>3.Expand /repeat-行</h3><p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/2020-08-24_19-29.png" alt="2020-08-24_19-29"></p>
<h4 id="3-1-expand"><a href="#3-1-expand" class="headerlink" title="3.1 expand"></a>3.1 expand</h4><p>参数是广播的目标tensor的shape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">14</span>,<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">b = torch.rand(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">b = b.unsqueeze(-<span class="number">1</span>).unsqueeze(-<span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">b1 = b.expand(<span class="number">4</span>,<span class="number">32</span>,<span class="number">14</span>,<span class="number">14</span>)<span class="comment">#之后b2即可以与a进行运算</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b1.shape)</span><br><span class="line"><span class="comment"># b2 = b.expand(4,33,14,14) 会报错 The expanded size of the tensor (33) must match the existing size (32) at non-singleton dimension 1</span></span><br><span class="line"></span><br><span class="line">b2 = b.expand(-<span class="number">1</span>,-<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) <span class="comment">#-1表示不想对该维度进行修改</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b2.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br></pre></td></tr></table></figure>

<h4 id="3-2-repeat－－不建议使用"><a href="#3-2-repeat－－不建议使用" class="headerlink" title="3.2 repeat－－不建议使用"></a>3.2 repeat－－不建议使用</h4><p>进行repeat之后，可能会开辟新的空间去保存repeat的结果，会降低效率</p>
<p><em>参数传递是每个维度上要重复的次数，需要自己计算</em></p>
<p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/2020-08-24_19-43.png" alt="2020-08-24_19-43"></p>
<h3 id="4-转置操作-t（只能适用于2D操作）"><a href="#4-转置操作-t（只能适用于2D操作）" class="headerlink" title="4.转置操作　.t（只能适用于2D操作）"></a>4.转置操作　.t（只能适用于2D操作）</h3><p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/2020-08-24_19-44.png" alt="2020-08-24_19-44"></p>
<h3 id="5-Transpose"><a href="#5-Transpose" class="headerlink" title="5.Transpose()"></a>5.Transpose()</h3><p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/2020-08-24_20-18.png" alt="2020-08-24_20-18"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#转换效果图</span></span><br><span class="line"></span><br><span class="line">a = torch.randn(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = torch.transpose(a,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">c = torch.transpose(a,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(<span class="number">2</span>,<span class="number">2</span>*<span class="number">3</span>).view(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">d = torch.transpose(a,<span class="number">1</span>,<span class="number">2</span>).contiguous().view(<span class="number">2</span>,<span class="number">2</span>*<span class="number">3</span>).view(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>).transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[-0.2507, -0.4298],</span></span><br><span class="line"><span class="string">         [-2.8421,  0.9166],</span></span><br><span class="line"><span class="string">         [ 3.2584,  1.1366]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.8887, -0.5606],</span></span><br><span class="line"><span class="string">         [ 1.3798, -0.5037],</span></span><br><span class="line"><span class="string">         [ 0.9862,  0.8550]]])</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">tensor([[[-0.2507, -2.8421,  3.2584],</span></span><br><span class="line"><span class="string">         [-0.4298,  0.9166,  1.1366]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.8887,  1.3798,  0.9862],</span></span><br><span class="line"><span class="string">         [-0.5606, -0.5037,  0.8550]]])</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">tensor([[[-0.2507, -2.8421],</span></span><br><span class="line"><span class="string">         [ 3.2584, -0.4298],</span></span><br><span class="line"><span class="string">         [ 0.9166,  1.1366]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.8887,  1.3798],</span></span><br><span class="line"><span class="string">         [ 0.9862, -0.5606],</span></span><br><span class="line"><span class="string">         [-0.5037,  0.8550]]])</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">tensor([[[-0.2507, -0.4298],</span></span><br><span class="line"><span class="string">         [-2.8421,  0.9166],</span></span><br><span class="line"><span class="string">         [ 3.2584,  1.1366]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.8887, -0.5606],</span></span><br><span class="line"><span class="string">         [ 1.3798, -0.5037],</span></span><br><span class="line"><span class="string">         [ 0.9862,  0.8550]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h3 id="6-permute"><a href="#6-permute" class="headerlink" title="6.permute"></a>6.permute</h3><p>permute也会打乱内存的顺序，需要调用coutigious函数</p>
<p>permute底层是调用多次transpose()实现的</p>
<p><img src="%E7%BB%B4%E5%BA%A6%E8%BD%AC%E6%8D%A2/2020-08-24_20-24.png" alt="2020-08-24_20-24"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#上面遮挡住的命令是</span></span><br><span class="line">b.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).shape</span><br><span class="line"><span class="comment">#out : torch.Size([4,28,32,3])</span></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/24/pytroch%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/24/pytroch%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87/" class="post-title-link" itemprop="url">pytroch索引与切片</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>
      

      <time title="Erstellt: 2020-08-24 07:33:55 / Geändert am: 08:45:12" itemprop="dateCreated datePublished" datetime="2020-08-24T07:33:55+08:00">2020-08-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="1-pytorch风格的索引－维度选择"><a href="#1-pytorch风格的索引－维度选择" class="headerlink" title="1.pytorch风格的索引－维度选择"></a>1.pytorch风格的索引－维度选择</h3><p>跟据Tensor的shape,从前往后索引，依次在每个维度上进行索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">a = torch.rand([<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>])</span><br><span class="line"><span class="built_in">print</span>( a[<span class="number">0</span>].shape)<span class="comment">#和Ｃ＋＋等高级问题类似，a[0]表示选择第一章图片</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>,<span class="number">0</span>].shape)<span class="comment">#选择第一章图片的第一个通道</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>])<span class="comment">#选择某个像素点，</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([3, 28, 28])</span></span><br><span class="line"><span class="string">torch.Size([28, 28])</span></span><br><span class="line"><span class="string">tensor(0.1076) #是维度为０的元素</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h3 id="2-python风格的索引-特定维度上"><a href="#2-python风格的索引-特定维度上" class="headerlink" title="2.python风格的索引-特定维度上"></a>2.python风格的索引-特定维度上</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">基本结构：</span></span><br><span class="line"><span class="string">eg : a[0,0,0:28:2,0]</span></span><br><span class="line"><span class="string">#0:28:2－－在某个维度上，start: end[:offset]  其中start:end:offset 表示从start开始，到end结束，其中不包括end，每次步长为offset;当省略offset时，表示offset=1</span></span><br><span class="line"><span class="string"># 0:28其实等价与 0:28:1这种结构</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">-1:表示倒数第１个元素，-2表示倒数第２个元素</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 譬如：4张图片，每张三个通道，每个通道28行28列的像素</span></span><br><span class="line">a = torch.rand(<span class="number">4</span>, <span class="number">3</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 在第一个维度上取后0和1，等同于取第一、第二张图片</span></span><br><span class="line"><span class="built_in">print</span>(a[:<span class="number">2</span>].shape)  </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 在第一个维度上取0和1,在第二个维度上取0，</span></span><br><span class="line"><span class="comment"># 等同于取第一、第二张图片中的第一个通道</span></span><br><span class="line"><span class="built_in">print</span>(a[:<span class="number">2</span>, :<span class="number">1</span>, :, :].shape)  </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 在第一个维度上取0和1,在第二个维度上取1,2，</span></span><br><span class="line"><span class="comment"># 等同于取第一、第二张图片中的第二个通道与第三个通道</span></span><br><span class="line"><span class="built_in">print</span>(a[:<span class="number">2</span>, <span class="number">1</span>:, :, :].shape) </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 在第一个维度上取0和1,在第二个维度上取1,2，</span></span><br><span class="line"><span class="comment"># 等同于取第一、第二张图片中的第二个通道与第三个通道</span></span><br><span class="line"><span class="built_in">print</span>(a[:<span class="number">2</span>, -<span class="number">2</span>:, :, :].shape)  </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用step隔行采样</span></span><br><span class="line"><span class="comment"># 在第一、第二维度取所有元素，在第三、第四维度步长为２采样</span></span><br><span class="line"><span class="comment"># 等同于所有图片所有通道的行列每个一行或者一列采样</span></span><br><span class="line"><span class="comment"># 注意：下面的代码不包括28</span></span><br><span class="line"><span class="built_in">print</span>(a[:, :, <span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>, <span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>].shape) </span><br><span class="line"><span class="built_in">print</span>(a[:, :, ::<span class="number">2</span>, ::<span class="number">2</span>].shape)  <span class="comment"># 等同于上面语句</span></span><br></pre></td></tr></table></figure>



<h3 id="3-选择特定的元素"><a href="#3-选择特定的元素" class="headerlink" title="3. 选择特定的元素"></a>3. 选择特定的元素</h3><h4 id="3-1-index-select"><a href="#3-1-index-select" class="headerlink" title="3.1 index_select"></a>3.1 index_select</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.index_select(input, dim, index, out=None) → Tensor</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">input (Tensor) – the input tensor.</span></span><br><span class="line"><span class="string">dim (int) – the dimension in which we index</span></span><br><span class="line"><span class="string">index (LongTensor) – the 1-D tensor containing the indices to index；是list转换成的一维tensor</span></span><br><span class="line"><span class="string">out (Tensor, optional) – the output tensor.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">a = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br><span class="line"><span class="built_in">print</span>((a.index_select(<span class="number">0</span>,torch.tensor([<span class="number">0</span>,<span class="number">2</span>]))).shape)</span><br><span class="line"><span class="comment">#选取第一个维度上的　索引为0,2的tensor</span></span><br><span class="line"><span class="comment">#第二个参数是将list [0,2]转换成 tensor</span></span><br><span class="line"><span class="built_in">print</span>((a.index_select(<span class="number">2</span>,torch.arange(<span class="number">8</span>))).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择第二维度上的前８个元素</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([4, 3, 28, 28])</span></span><br><span class="line"><span class="string">torch.Size([2, 3, 28, 28])</span></span><br><span class="line"><span class="string">torch.Size([4, 3, 8, 28])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>索引效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">a = torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>((a.index_select(<span class="number">0</span>,torch.tensor([<span class="number">0</span>,<span class="number">2</span>]))))</span><br><span class="line"><span class="built_in">print</span>((a.index_select(<span class="number">1</span>,torch.arange(<span class="number">2</span>))))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0.9071, 0.5350, 0.4018],</span></span><br><span class="line"><span class="string">        [0.9565, 0.9739, 0.7234],</span></span><br><span class="line"><span class="string">        [0.1984, 0.3562, 0.8078]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[0.9071, 0.5350, 0.4018],</span></span><br><span class="line"><span class="string">        [0.1984, 0.3562, 0.8078]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[0.9071, 0.5350],</span></span><br><span class="line"><span class="string">        [0.9565, 0.9739],</span></span><br><span class="line"><span class="string">        [0.1984, 0.3562]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h4 id="3-2-masked-select"><a href="#3-2-masked-select" class="headerlink" title="3.2 masked_select()"></a>3.2 masked_select()</h4><h6 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">函数说明</span></span><br><span class="line"><span class="string">torch.masked_select( input, mask ,out = None ) -&gt; 张量</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">根据掩码张量mask中的二元值(0,1)，取输入张量中的指定项( mask为一个 ByteTensor)，将取值返回到一个新的1D张量－－－是打平的张量; 张量 mask须跟input张量有相同数量的元素数目，但形状或维度不需要相同。</span></span><br><span class="line"><span class="string">注意： 返回的张量不与原始张量共享内存空间。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">mask2 = a.ge(<span class="number">0.3</span>)</span><br><span class="line">mask3 = a.le(<span class="number">0.7</span>)</span><br><span class="line"><span class="built_in">print</span>(mask2)</span><br><span class="line"><span class="built_in">print</span>(a[mask2])</span><br><span class="line"><span class="built_in">print</span>(a[mask3])</span><br><span class="line"><span class="built_in">print</span>(torch.masked_select(a,mask2))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[-0.7769, -0.0803, -0.4235, -0.3562],</span></span><br><span class="line"><span class="string">        [-0.4744,  1.2078,  0.6371, -0.6981],</span></span><br><span class="line"><span class="string">        [-1.1653, -0.3432, -2.3189,  0.1708]])</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">tensor([[ True, False,  True,  True],</span></span><br><span class="line"><span class="string">        [False, False, False, False],</span></span><br><span class="line"><span class="string">        [ True, False, False, False]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([1.2078, 0.6371])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor([-0.7769, -0.0803, -0.4235, -0.3562, -0.4744,  0.6371, -0.6981, -1.1653,</span></span><br><span class="line"><span class="string">        -0.3432, -2.3189,  0.1708])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([1.2078, 0.6371])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h6 id="方式二-不使用a-ge-a-le-方法"><a href="#方式二-不使用a-ge-a-le-方法" class="headerlink" title="方式二　不使用a.ge() \ a.le()方法"></a>方式二　不使用a.ge() \ a.le()方法</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a = torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">mask1 = torch.ByteTensor((a&gt;<span class="number">0.5</span>).byte())　</span><br><span class="line"><span class="built_in">print</span>(mask1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a[mask1])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出：</span></span><br><span class="line"><span class="string">tensor([[-1.8973, -0.2158,  1.0196, -0.2119],</span></span><br><span class="line"><span class="string">        [-0.2365,  0.4743, -1.2473, -0.6554],</span></span><br><span class="line"><span class="string">        [ 0.3040, -0.0906, -0.8517, -0.2679]])</span></span><br><span class="line"><span class="string">tensor([[0, 0, 1, 0],</span></span><br><span class="line"><span class="string">        [0, 0, 0, 0],</span></span><br><span class="line"><span class="string">        [0, 0, 0, 0]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([1.0196])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">提醒一下：不是特别建议使用这种方式</span></span><br><span class="line"><span class="string"> UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> 感觉自己对python和pytorch基本类型的转换有些模糊　－－－torch.bool　与　torch.uint8</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h4 id="3-2-torch-take"><a href="#3-2-torch-take" class="headerlink" title="3.2 torch.take()"></a>3.2 torch.take()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">使用打平的index进行索引</span></span><br><span class="line"><span class="string">torch.take(input, index) -&gt;Tensor</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">index(Long Tensor) 把input Tensor看作一维Tensor对每个元素的索引</span></span><br><span class="line"><span class="string">输出:一个一维Tensor</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.randn(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = torch.take(a, torch.tensor([<span class="number">1</span>,<span class="number">5</span>,<span class="number">7</span>]))</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">输出：</span></span><br><span class="line"><span class="string">tensor([[-0.3353,  1.2220,  0.7055,  0.4678],</span></span><br><span class="line"><span class="string">        [-0.4759,  0.5173,  1.1912, -0.8545],</span></span><br><span class="line"><span class="string">        [-1.2037,  0.5052,  0.0388, -0.3160]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([ 1.2220,  0.5173, -0.8545])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/23/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%BC%95%E5%85%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/23/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%BC%95%E5%85%A5/" class="post-title-link" itemprop="url">分类问题的引入</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-08-23 15:54:03" itemprop="dateCreated datePublished" datetime="2020-08-23T15:54:03+08:00">2020-08-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-24 08:45:00" itemprop="dateModified" datetime="2020-08-24T08:45:00+08:00">2020-08-24</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h2><p><strong>MNIST　数据集</strong></p>
<p>由不同风格的手写数字组成(0-9)</p>
<p>每个数字都有7000张，每张图片都是28*28的灰度图片</p>
<p>训练时：将训练集和测试集分为60k Vs 10k</p>
<h3 id="1-No-deeping-learning"><a href="#1-No-deeping-learning" class="headerlink" title="1. No deeping learning"></a>1. No deeping learning</h3><p>X:[1….28*28]</p>
<p>每个点都是０－１，表示该像素点的灰度值</p>
<p>关键点：参数的维度定义，以及每层转换的含义</p>
<p><img src="%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%BC%95%E5%85%A5/2020-08-22_16-28.png" alt="2020-08-22_16-28"></p>
<p><img src="%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%BC%95%E5%85%A5/2020-08-22_16-55.png" alt="2020-08-22_16-55"></p>
<p><img src="%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%BC%95%E5%85%A5/2020-08-22_16-57.png" alt="2020-08-22_16-57"></p>
<p>2.代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-encodng: utf-8-*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@File: minist.py.py</span></span><br><span class="line"><span class="string">@Contact: 2257925767@qq.com</span></span><br><span class="line"><span class="string">@Author:wangyu</span></span><br><span class="line"><span class="string">@Version:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@Desciption:</span></span><br><span class="line"><span class="string">        手写数字识别的核心代码</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        还存在一些问题没有解决－－－自己得到的数据比老师的代码迭代的次数要少很多</span></span><br><span class="line"><span class="string">    env: </span></span><br><span class="line"><span class="string">        pytorch 1.3.1</span></span><br><span class="line"><span class="string">@DateTime: 2020/8/22下午5:04 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F <span class="comment">#常见的激活函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> plot_image, plot_curve, one_hot</span><br><span class="line"></span><br><span class="line"><span class="comment"># step1 . load dataset,采用向量并行</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">512</span></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    torchvision.datasets.MNIST(<span class="string">&quot;mnist_data&quot;</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,</span><br><span class="line">                               transform= torchvision.transforms.Compose([torchvision.transforms.ToTensor(),<span class="comment">#将numby格式数据转成pytorch</span></span><br><span class="line">                                                                            torchvision.transforms.Normalize(</span><br><span class="line">                                                                                (<span class="number">0.1307</span>,),(<span class="number">0.3081</span>,)), <span class="comment">#对像素点的灰度值进行正则化，会提高优化效率</span></span><br><span class="line">                                                                          ])),batch_size = batch_size,shuffle = <span class="literal">True</span>)<span class="comment">#随机打散</span></span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    torchvision.datasets.MNIST(<span class="string">&quot;mnist_data/&quot;</span>,train=<span class="literal">False</span>,download=<span class="literal">True</span>,</span><br><span class="line">                               transform= torchvision.transforms.Compose([torchvision.transforms.ToTensor(),<span class="comment">#将numby格式数据转成pytorch</span></span><br><span class="line">                                                                            torchvision.transforms.Normalize(</span><br><span class="line">                                                                                (<span class="number">0.1307</span>,),(<span class="number">0.3081</span>,)), <span class="comment">#对像素点的灰度值进行正则化，会提高优化效率</span></span><br><span class="line">                                                                          ])),batch_size = batch_size,shuffle = <span class="literal">False</span>)<span class="comment">#随机打散</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="built_in">print</span>(x.shape,y.shape,x.<span class="built_in">min</span>(),x.<span class="built_in">max</span>())</span><br><span class="line">plot_image(x,y,<span class="string">&#x27;image_test&#x27;</span>) <span class="comment">#检查数据集</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span><span class="comment">#初始化函数:搭建网络结构</span></span><br><span class="line">        <span class="built_in">super</span>(Net,self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#wx+b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">28</span>*<span class="number">28</span>,<span class="number">256</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">256</span>,<span class="number">64</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">64</span>,<span class="number">10</span>)<span class="comment">#28*28 =&gt; 256 =&gt;64这个是随机确定的,最后一层的输出是由分类的种类数决定的</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span><span class="comment">#网络的计算过程</span></span><br><span class="line">        <span class="comment"># x :[batch_size,1,28,28] 1:表示只有一个通道</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#h1= relu(xw1+b1)</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment">#h1=relu(h1w2+b2)</span></span><br><span class="line">        x=F.relu(self.fc2(x))</span><br><span class="line">        <span class="comment">#h3=h2w3+b3 --这里没有使用激活函数，只是简单输出</span></span><br><span class="line">        x=self.fc3(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net()<span class="comment">#实例化一个net</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义优化器</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(),lr=<span class="number">0.01</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">train_loss=[]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">for</span> batch_idx , (x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader): <span class="comment">#迭代一次数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.调整数据的尺寸，构建网络，通过网络计算预测值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#x: [b,1,28,28], y:[512]</span></span><br><span class="line">        <span class="comment"># [b,1,28,28] =&gt; [b,784]</span></span><br><span class="line">        x =x.view(x.size(<span class="number">0</span>),<span class="number">28</span>*<span class="number">28</span>) <span class="comment">#size[0]表示batch_size</span></span><br><span class="line">        <span class="comment">#=&gt;[b,10]</span></span><br><span class="line">        out = net(x) <span class="comment">#经过网络计算出来的值</span></span><br><span class="line">        y_onehot = one_hot(y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.定义梯度</span></span><br><span class="line">        <span class="comment">#loss = mse_loss(out,y_onehot) 欧式距离</span></span><br><span class="line">        loss = F.mse_loss(out,y_onehot)</span><br><span class="line"><span class="comment">#3.梯度清０</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.梯度计算过程</span></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.参数更新</span></span><br><span class="line">        <span class="comment">#w&#x27;= w-lr*grad</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        train_loss.append(loss.item())<span class="comment">#loss: tensor =&gt; numpy</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(epoch,batch_idx,loss.item())</span><br><span class="line"></span><br><span class="line">plot_curve(train_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">#get optimal[w1,b2,w2,b2,w3,b3]</span></span><br><span class="line"></span><br><span class="line">total_correct = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> test_loader:</span><br><span class="line">    x = x.view(x.size(<span class="number">0</span>),<span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">    out = net(x)</span><br><span class="line">    <span class="comment">#out = net(x)</span></span><br><span class="line">    pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    correct = pred.eq(y).<span class="built_in">sum</span>().<span class="built_in">float</span>().item()</span><br><span class="line">    total_correct+= correct</span><br><span class="line"></span><br><span class="line">total_num = <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">acc=total_correct/total_num</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;test acc:&#x27;</span>,acc)</span><br><span class="line"></span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_loader))</span><br><span class="line">out = net(x.view(x.size(<span class="number">0</span>),<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line">plot_image(x,pred,<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-encodng: utf-8-*-</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@File: util.py.py</span></span><br><span class="line"><span class="string">@Contact: 2257925767@qq.com</span></span><br><span class="line"><span class="string">@Author:wangyu</span></span><br><span class="line"><span class="string">@Version:</span></span><br><span class="line"><span class="string">        手写数字识别的工具文件</span></span><br><span class="line"><span class="string">@Desciption:</span></span><br><span class="line"><span class="string">    env: </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@DateTime: 2020/8/22下午5:04 </span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span>  torch</span><br><span class="line"><span class="keyword">from</span>    matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_curve</span>(<span class="params">data</span>):</span><span class="comment">#计算训练曲线</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(data)), data, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;value&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;step&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;value&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_image</span>(<span class="params">img, label, name</span>):</span><span class="comment">#展现出识别结果</span></span><br><span class="line"></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">        plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.imshow(img[i][<span class="number">0</span>]*<span class="number">0.3081</span>+<span class="number">0.1307</span>, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name, label[i].item()))</span><br><span class="line">        plt.xticks([])</span><br><span class="line">        plt.yticks([])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_hot</span>(<span class="params">label, depth=<span class="number">10</span></span>):</span><span class="comment">#完成one-hot编码</span></span><br><span class="line">    out = torch.zeros(label.size(<span class="number">0</span>), depth)</span><br><span class="line">    idx = torch.LongTensor(label).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    out.scatter_(dim=<span class="number">1</span>, index=idx, value=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/23/%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/23/%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">简单的回归问题</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-08-23 15:53:54" itemprop="dateCreated datePublished" datetime="2020-08-23T15:53:54+08:00">2020-08-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-28 14:36:26" itemprop="dateModified" datetime="2020-08-28T14:36:26+08:00">2020-08-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="简单的回归问题"><a href="#简单的回归问题" class="headerlink" title="简单的回归问题"></a>简单的回归问题</h2><h3 id="１．从简单到复杂"><a href="#１．从简单到复杂" class="headerlink" title="１．从简单到复杂"></a>１．从简单到复杂</h3><p>==梯度下降算法==：梯度是深度学习的核心</p>
<p>１.简单的小例子</p>
<p><img src="%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/2020-08-22_06-44.png" alt="2020-08-22_06-44"></p>
<p>２.问题的迭代</p>
<p>求解$y = wx+b$　二元一次方程$w, b$的值</p>
<p>　　i.中学阶段：　求解二元一次方程的方法－－&gt;消元法(利用Closed Form Solution精确求得ｗ,b的解)</p>
<p>​        ii.引入噪音(noise：），模拟现实情况，我们的目标并不是为了得到一个精确解，而是得到一个从经验上精度可行的近似解即可，</p>
<p>解决方法：需要更多的样本点＋之后采用梯度下降算法求解</p>
<p>​        iii.首先构造一个函数(均方差)，因为梯度下降算法是求解极值的算法</p>
<p>​<br>$$<br>loss = (y-wx-b)^2<br>$$<br>$loss$方程值最小所对应的$w,b$ 可以近似认为是二元一次方程的解</p>
<p>​        注:在实际问题中，首先根据样本分布的情况，选择它可能对应的方程（二元一次，二元二次….)</p>
<p>​        V:优化过程（Convex Optimization-凸优化问题)</p>
<p><img src="%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/2020-08-22_06-57.png" alt="2020-08-22_06-57"></p>
<p>​        针对于一个样本来讲<br>$$<br>对于loss函数，变量ｗ,b；按照梯度下降的算法求loss的极值\<br>            找到loss最小时，对应的w,b\<br>            通过梯度迭代更新\<br>initial : w=0,b=0</p>
<p>\<br>b = b+ learningRate* \partial w\<br>w = w+ learningRate*\partial b</p>
<p>\<br>\partial w = 2(y-wx-b)*(-x)<br>\<br>\partial b= 2(y-wx-b)(-1)<br>$$</p>
<p>之后编程实现的是在Ｎ个样本上的问题</p>
<p><img src="%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/2020-08-22_06-59.png" alt="2020-08-22_06-59"></p>
<p>​        </p>
<h3 id="2-问题类型"><a href="#2-问题类型" class="headerlink" title="2.问题类型"></a>2.问题类型</h3><p><img src="%E7%AE%80%E5%8D%95%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/2020-08-22_07-01.png" alt="2020-08-22_07-01"></p>
<h3 id="3-二元一次方程-编程实现"><a href="#3-二元一次方程-编程实现" class="headerlink" title="3. 二元一次方程　编程实现"></a>3. 二元一次方程　编程实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computer_error_for_line_given_points</span>(<span class="params">b,w,points</span>):</span> <span class="comment">##计算错误率</span></span><br><span class="line">    totalError = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points)):</span><br><span class="line">        x=points[i,<span class="number">0</span>]</span><br><span class="line">        y=points[i,<span class="number">1</span>]</span><br><span class="line">        totalError += (y-(w*x+b))**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> totalError/(<span class="built_in">float</span>)(<span class="built_in">len</span>(points))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_gradient</span>(<span class="params">b_current,w_current,points,learningRate</span>):</span><span class="comment">##在所有的节点上进行，一次梯度下降，更新参数</span></span><br><span class="line">    b_gradient=<span class="number">0</span></span><br><span class="line">    w_gradient=<span class="number">0</span></span><br><span class="line">    N= <span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(points)):</span><br><span class="line">        x=points[i,<span class="number">0</span>]</span><br><span class="line">        y=points[i,<span class="number">1</span>]</span><br><span class="line">        b_gradient += -(<span class="number">2</span>/N) *(y-((w_current*x)+b_current))</span><br><span class="line">        w_gradient += -(<span class="number">2</span>/N)*x*(y-((w_current*x)+b_current))</span><br><span class="line">    new_b = b_current -(learningRate*b_gradient)</span><br><span class="line">    new_w = w_current -(learningRate*w_gradient)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>[new_b,new_w]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent_runner</span>(<span class="params">points,starting_b,starting_w,learning_rate,num_iterator</span>):</span></span><br><span class="line"></span><br><span class="line">    b= starting_b</span><br><span class="line">    w= starting_w</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterator):</span><br><span class="line">        b,w = step_gradient(b,w,np.array(points),learning_rate)<span class="comment">#这里应该是没有选择最小的loss只是把最后迭代的结果返回</span></span><br><span class="line">    <span class="keyword">return</span> [b,w]</span><br><span class="line"></span><br><span class="line"><span class="comment">#这里没有数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>():</span></span><br><span class="line">    points = np.genfromtxt(<span class="string">&quot;/home/doriswang/workplace/coding/pytorch_learning/venv/include/2.1/data.csv&quot;</span>,delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    <span class="comment"># print(points)</span></span><br><span class="line">    learning_rate =<span class="number">0.0001</span></span><br><span class="line">    initial_b =<span class="number">0</span></span><br><span class="line">    initial_w =<span class="number">0</span></span><br><span class="line">    num_iterations = <span class="number">1000</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting gradient descent at b=&#123;0&#125; , w=&#123;1&#125; ,error =&#123;2&#125;&quot;</span>.<span class="built_in">format</span>(initial_b,initial_w,computer_error_for_line_given_points(initial_b,initial_w,points)))</span><br><span class="line">    [b,w]=gradient_descent_runner(points,initial_b,initial_w,learning_rate,num_iterations)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;After &#123;0&#125; iterations b=&#123;1&#125;,w=&#123;2&#125;,error=&#123;3&#125;&quot;</span>.<span class="built_in">format</span>(num_iterations,b,w,computer_error_for_line_given_points(b,w,points)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/23/%E5%88%9D%E8%AF%86pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/23/%E5%88%9D%E8%AF%86pytorch/" class="post-title-link" itemprop="url">初始pytorch</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-08-23 15:53:10" itemprop="dateCreated datePublished" datetime="2020-08-23T15:53:10+08:00">2020-08-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-28 14:36:18" itemprop="dateModified" datetime="2020-08-28T14:36:18+08:00">2020-08-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="初试深度学习"><a href="#初试深度学习" class="headerlink" title="初试深度学习"></a>初试深度学习</h2><h3 id="1-深度学习框架"><a href="#1-深度学习框架" class="headerlink" title="1.深度学习框架"></a>1.深度学习框架</h3><p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_19-40.png" alt="2020-08-21_19-40"></p>
<p>==pytorch &amp;&amp; tensorflow的本质区别在于动态图优先还是静态图优先==</p>
<p>1.动态优先图–pytorch</p>
<p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_19-53.png" alt="2020-08-21_19-53"></p>
<p>2.静态图的方式–tensorflow</p>
<p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_19-59.png" alt="2020-08-21_19-59"></p>
<p>1.首先先建立一个计算图（框架）</p>
<p>2.向计算图传递参数来运行计算图</p>
<p>在计算图运行过程中，我们不能干预，调试或者动态改变比较麻烦</p>
<h4 id="综合评价"><a href="#综合评价" class="headerlink" title="综合评价"></a>综合评价</h4><p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_20-04.png" alt="2020-08-21_20-04"></p>
<h3 id="２-pytorch的生态"><a href="#２-pytorch的生态" class="headerlink" title="２.pytorch的生态"></a>２.pytorch的生态</h3><p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_20-10.png" alt="2020-08-21_20-10"></p>
<h3 id="３-pytorch的优势"><a href="#３-pytorch的优势" class="headerlink" title="３.pytorch的优势"></a>３.pytorch的优势</h3><p>１.使用GPU进行加速</p>
<p>２.自动求导</p>
<p>３.常用网络层</p>
<p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_20-19.png" alt="2020-08-21_20-19"></p>
<h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><p><img src="%E5%88%9D%E5%A7%8Bpytorch/2020-08-21_20-26.png" alt="2020-08-21_20-26"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/23/pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/23/pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/" class="post-title-link" itemprop="url">pytorch基础语法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-08-23 12:16:28" itemprop="dateCreated datePublished" datetime="2020-08-23T12:16:28+08:00">2020-08-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-25 08:47:30" itemprop="dateModified" datetime="2020-08-25T08:47:30+08:00">2020-08-25</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="1-基本数据类型"><a href="#1-基本数据类型" class="headerlink" title="1 基本数据类型"></a>1 基本数据类型</h2><h3 id="1-1-python中数据类型与torch中数据类型的对比"><a href="#1-1-python中数据类型与torch中数据类型的对比" class="headerlink" title="1.1 python中数据类型与torch中数据类型的对比"></a>1.1 python中数据类型与torch中数据类型的对比</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_18-08.png" alt="2020-08-23_18-08"></p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_18-12.png" alt="2020-08-23_18-12"></p>
<p>《下图中常用的数据类型使用红色方框表示出来》</p>
<h3 id="1-2-pytorch中String的表示方法"><a href="#1-2-pytorch中String的表示方法" class="headerlink" title="1.2 pytorch中String的表示方法"></a>1.2 pytorch中String的表示方法</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_18-10.png" alt="2020-08-23_18-10"></p>
<h3 id="1-3-pytorch中CPU和GPU数据类型的区别"><a href="#1-3-pytorch中CPU和GPU数据类型的区别" class="headerlink" title="1.3　pytorch中CPU和GPU数据类型的区别"></a>1.3　pytorch中CPU和GPU数据类型的区别</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_17-07.png" alt="2020-08-23_17-07"></p>
<p>如果在GPU上面，则需要将其数据类型转换:<br>方法：``data=data.cuda()`　，调用此函数会返回一个ＧＰＵ上的一个应用</p>
<h3 id="1-4-torch中数据类型的判断"><a href="#1-4-torch中数据类型的判断" class="headerlink" title="1.4 torch中数据类型的判断"></a>1.4 torch中数据类型的判断</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># torch中的数据类型</span></span><br><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">3</span>)<span class="comment">#随机初始化一个两行三列的数据</span></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">type</span>()) <span class="comment">#查看数据类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">isinstance</span>(a,torch.FloatTensor)) <span class="comment">#数据类型合法性检验</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">isinstance</span>(a,torch.IntTensor))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">torch.FloatTensor</span></span><br><span class="line"><span class="string">&lt;class &#x27;torch.Tensor&#x27;&gt;</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="1-5-Tensor的形状"><a href="#1-5-Tensor的形状" class="headerlink" title="1.5 Tensor的形状"></a>1.5 Tensor的形状</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_18-57.png" alt="2020-08-23_18-57"></p>
<p><code>data.shape</code>, <code>data.size()</code>,<code>data.dim()</code>,<code>data.numel()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dim =  size(data.shape) ,表示数据的深度／维度</span></span><br><span class="line"><span class="comment"># size=shape，表示数据的形状，记录每一维度的长度</span></span><br><span class="line"><span class="comment"># numel:表示tensor占用内存的长度</span></span><br><span class="line">d4 = torch.FloatTensor(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(d4.size())</span><br><span class="line"><span class="built_in">print</span>(d4.shape)</span><br><span class="line"><span class="built_in">print</span>(d4.dim())</span><br><span class="line"><span class="built_in">print</span>(d4.size(<span class="number">0</span>)) <span class="comment">#可以进行索引，某维度的长度，为了更好地与python进行交互，一般直接将size和shape转换成list</span></span><br><span class="line"><span class="built_in">print</span>(d4.size(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">torch.Size([2, 3])</span></span><br><span class="line"><span class="string">torch.Size([2, 3])</span></span><br><span class="line"><span class="string">2</span></span><br><span class="line"><span class="string">2</span></span><br><span class="line"><span class="string">3</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_19-00.png" alt="2020-08-23_19-00"></p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_19-19.png" alt="2020-08-23_19-19"></p>
<h3 id="1-6-Dim-0的数据"><a href="#1-6-Dim-0的数据" class="headerlink" title="1.6 Dim 0的数据"></a>1.6 Dim 0的数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">a=torch.tensor(<span class="number">1.0</span>)</span><br><span class="line"><span class="built_in">print</span>(a.shape) <span class="comment">#1.0/tensor(1.)是0维的是标量，但是[1.]是１维长度为１的Tensor</span></span><br><span class="line">                			<span class="comment">#标量的应用：计算的loss函数都是标量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(a.shape))</span><br><span class="line"><span class="built_in">print</span>(a.size())</span><br><span class="line"><span class="built_in">print</span>(torch.tensor(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">torch.Size([]),这里表示size中的‘list&#x27;长度为０</span></span><br><span class="line"><span class="string">0</span></span><br><span class="line"><span class="string">torch.Size([])</span></span><br><span class="line"><span class="string">tensor(2)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>标量的用途：　1.常见是在计算loss函数的结果是用标量表示的</p>
<h3 id="1-7-Dim-1的数据"><a href="#1-7-Dim-1的数据" class="headerlink" title="1.7 Dim 1的数据"></a>1.7 Dim 1的数据</h3><p>常用于  1. Bias: wx+b 中的 b         2. Linear Input 例如，手写数字识别中的28*28 可以看作长度为784的一维数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##Dim 1/ rank 1</span></span><br><span class="line"><span class="comment">#其实在tensor 0.3 之前没有dim=0的Tensor，实际上维度为１，size=1的数即可表示标量,不过0.4之后把他们区分开了</span></span><br><span class="line"></span><br><span class="line">a1=torch.tensor([<span class="number">1.1</span>])<span class="comment">#dim=1,size=1</span></span><br><span class="line">a2=torch.tensor([<span class="number">1.1</span>,<span class="number">2.2</span>]) <span class="comment"># dim=1,size=2</span></span><br><span class="line"></span><br><span class="line">a3=torch.FloatTensor(<span class="number">1</span>) <span class="comment">#这里的参数指定的是Dim１的长度，随机初始化</span></span><br><span class="line"><span class="built_in">print</span>(a1.size())</span><br><span class="line"><span class="built_in">print</span>(a2.size())</span><br><span class="line"><span class="built_in">print</span>(a3.shape)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch.Size([1])</span></span><br><span class="line"><span class="string">torch.Size([2])</span></span><br><span class="line"><span class="string">torch.Size([1])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="1-8-Dim２的数据"><a href="#1-8-Dim２的数据" class="headerlink" title="1.8 Dim２的数据"></a>1.8 Dim２的数据</h3><p>常用场景：　1. Linear Input batch [ batch_size , features_num]</p>
<p>a=torch.tensor([4,784])<br>其中4是指数据图片的数目，而784是指每一张图片的特征维度<br>适用于普通的机器学习数据</p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_19-12_1.png" alt="2020-08-23_19-12_1"></p>
<h3 id="1-9-Dim-3的数据"><a href="#1-9-Dim-3的数据" class="headerlink" title="1.9 Dim 3的数据"></a>1.9 Dim 3的数据</h3><p><strong>RNN Input Batch</strong>　[batch_size, sentence_num, word_one_sentence]</p>
<p>例如，对于RNN神经网络进行语音识别与处理时[10,20,100]表示:每个单词包含100个特征，一句话一共有10个单词，而每次输20句话</p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_19-12.png" alt="2020-08-23_19-12"></p>
<h3 id="1-10-Dim-4-的数据"><a href="#1-10-Dim-4-的数据" class="headerlink" title="1.10 Dim 4 的数据"></a>1.10 Dim 4 的数据</h3><p><strong>CNN input Batch</strong> [batch_size, channel_num, height, weight ]　</p>
<p>通道数，图片的高度，图片的宽度</p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_19-19_1.png" alt="2020-08-23_19-19_1"></p>
<h2 id="2-创建Tensor"><a href="#2-创建Tensor" class="headerlink" title="2.创建Tensor"></a>2.创建Tensor</h2><h3 id="1-Import-from-numpy"><a href="#1-Import-from-numpy" class="headerlink" title="1. Import from numpy"></a>1. Import from numpy</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">2</span>,<span class="number">3.3</span>]) <span class="comment"># 数据实际是double类型</span></span><br><span class="line"><span class="built_in">print</span>(torch.from_numpy(a))</span><br><span class="line"></span><br><span class="line">a = np.ones([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(torch.from_numpy(a))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([2.0000, 3.3000], dtype=torch.float64)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor([[1., 1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1., 1.]], dtype=torch.float64)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h3 id="2-Import-from-list"><a href="#2-Import-from-list" class="headerlink" title="2. Import from list"></a>2. Import from list</h3><p><strong>关于参数传递的小问题</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor / FloatTensor /IntTensor　等既可以传递数值型，也可以传递shape相关的类型的数据</span><br><span class="line">tensor只能传递数据list作为参数</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([<span class="number">2.</span>,<span class="number">3.2</span>])</span><br><span class="line">b = torch.tensor([[<span class="number">2.</span>,<span class="number">2.3</span>],[<span class="number">1.</span>,<span class="number">2.34</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">a2 = torch.FloatTensor([<span class="number">2.</span>,<span class="number">3.2</span>])<span class="comment">##不建议用该方法，tensor可以 代替</span></span><br><span class="line">a3 = torch.FloatTensor(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>) <span class="comment">#建议传递参数为shape参数</span></span><br><span class="line"><span class="built_in">print</span>(a2)</span><br><span class="line"><span class="built_in">print</span>(a3)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;        </span></span><br><span class="line"><span class="string">tensor([2.0000, 3.2000])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor([[2.0000, 2.3000],</span></span><br><span class="line"><span class="string">        [1.0000, 2.3400]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([2.0000, 3.2000])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor([[[ 2.0281e+15,  4.5682e-41,  2.5162e-26,  4.5682e-41],</span></span><br><span class="line"><span class="string">         [ 2.0260e+15,  4.5682e-41,  2.5162e-26,  4.5682e-41],</span></span><br><span class="line"><span class="string">         [ 2.0260e+15,  4.5682e-41,  2.5157e-26,  4.5682e-41]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 2.0284e+15,  4.5682e-41,  2.6360e-26,  4.5682e-41],</span></span><br><span class="line"><span class="string">         [ 3.6957e+15,  4.5682e-41,  2.6361e-26,  4.5682e-41],</span></span><br><span class="line"><span class="string">         [ 2.0284e+15,  4.5682e-41, -2.9008e+29,  3.0639e-41]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="3-未初始化的数据"><a href="#3-未初始化的数据" class="headerlink" title="3. 未初始化的数据"></a>3. 未初始化的数据</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_20-25.png" alt="2020-08-23_20-25"></p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-23_20-29.png" alt="2020-08-23_20-29"></p>
<h3 id="4-随机初始化"><a href="#4-随机初始化" class="headerlink" title="4.随机初始化"></a>4.随机初始化</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#相关函数</span><br><span class="line">torch.rand(Tensor.shape)　#生成一个[0,1)之间的随机数</span><br><span class="line">torch.randlike(Tensor tt)</span><br><span class="line"></span><br><span class="line">torch.randint(  int low , int high , [d1,d2....])#均匀采样，只采整数值</span><br><span class="line">torch.randint_like(Tensor tt ,int low, int high) </span><br></pre></td></tr></table></figure>

<p>代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">a= torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># a1 = torch.rand()</span></span><br><span class="line"></span><br><span class="line">b = torch.rand_like(a)<span class="comment">#会生成与ａ尺寸大小相同的随机数的tensor</span></span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">c = torch.randint(<span class="number">1</span>,<span class="number">99</span>,[<span class="number">3</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line">d = torch.randint_like(c,<span class="number">1</span>,<span class="number">10</span>) <span class="comment">#使用randint一定要指出数据范围</span></span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[0.9843, 0.0908, 0.6296],</span></span><br><span class="line"><span class="string">        [0.5270, 0.4654, 0.3570],</span></span><br><span class="line"><span class="string">        [0.9419, 0.1018, 0.1724]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[0.3775, 0.3013, 0.3237],</span></span><br><span class="line"><span class="string">        [0.6003, 0.1313, 0.1082],</span></span><br><span class="line"><span class="string">        [0.7574, 0.4202, 0.0610]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[20, 93, 85],</span></span><br><span class="line"><span class="string">        [20, 81, 95],</span></span><br><span class="line"><span class="string">        [22, 10, 88]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[8, 9, 8],</span></span><br><span class="line"><span class="string">        [2, 7, 4],</span></span><br><span class="line"><span class="string">        [1, 4, 9]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="5-生成正态分布"><a href="#5-生成正态分布" class="headerlink" title="5.生成正态分布"></a>5.生成正态分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#相关函数说明</span></span><br><span class="line">tensor.normal(mean,std,*,generator=<span class="literal">None</span>,out = <span class="literal">None</span>) -&gt;Tensor</span><br><span class="line"><span class="comment">#参数说明:该方法只能生成一维,需要进行形状变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. mean, std可以都为tensor，此时可以为每个元素指定分布来源</span></span><br><span class="line"><span class="comment">#2. mean,std可以一个为float/tensor，此时最后生成的Tensor的尺寸mean/std(数据类型为tensor)决定，此时所有数据共享均值或者方差</span></span><br><span class="line"><span class="comment">#3. mean,std都为float时，要求指明参数，此时所有数据都来源一个分布</span></span><br><span class="line"></span><br><span class="line">tensor,randn(*size , out = <span class="literal">None</span>, dtype = <span class="literal">None</span>,....)<span class="comment">#参数列表没有列全</span></span><br><span class="line"><span class="comment">#从平均值为0，方差为1的正态分布中返回一个填充有随机数的张量（也称为标准正态分布</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">a1 = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment">#从平均值为0，方差为1的正态分布中返回一个填充有随机数的张量，形状由参数决定（也称为标准正态分布）</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a1)</span><br><span class="line"></span><br><span class="line"><span class="comment">#关于torch.normal：比较灵活，掌握一种方式就行</span></span><br><span class="line"><span class="comment">#方式１：保证mean和std的尺寸相同</span></span><br><span class="line">a = torch.normal( mean = torch.arange(<span class="number">1.</span>,<span class="number">11.</span>),std = torch.arange(<span class="number">1</span>,<span class="number">0</span>,-<span class="number">0.1</span>))</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment">#方式２：</span></span><br><span class="line">b = torch.normal(mean = torch.full([<span class="number">10</span>],<span class="number">0</span>),std = <span class="number">0.5</span>) <span class="comment">#这种方式也是可以实现所有数据来自一个分布</span></span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">c = torch.normal(mean = <span class="number">10</span>, std = torch.arange(<span class="number">5</span>,<span class="number">0</span>,-<span class="number">0.5</span>))</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="comment">#方式３</span></span><br><span class="line">d = torch.normal(<span class="number">10</span>,<span class="number">0.1</span>,size=(<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[-0.6377,  0.0554, -0.7616],</span></span><br><span class="line"><span class="string">        [ 0.1244, -0.1076,  0.2659]])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([-1.5609,  0.1449,  2.7791,  3.4830,  4.6098,  5.9147,  7.2475,  8.0593,</span></span><br><span class="line"><span class="string">         9.3134, 10.0676])</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">tensor([ 0.8977, -0.6111, -0.2214, -0.0326,  0.4336, -0.2131, -0.0297, -0.0359,</span></span><br><span class="line"><span class="string">         0.0294, -0.3355])</span></span><br><span class="line"><span class="string">         </span></span><br><span class="line"><span class="string">tensor([11.8549, 12.7589, 13.7979, 12.9034,  8.1115, 15.1006, 13.7763, 12.9549,10.0838, 10.1662])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tensor([[10.0064,  9.8803,  9.9584],</span></span><br><span class="line"><span class="string">        [10.1267, 10.2988,  9.8402]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="6-生成元素相同的tensor"><a href="#6-生成元素相同的tensor" class="headerlink" title="6.生成元素相同的tensor"></a>6.生成元素相同的tensor</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-24_00-13.png" alt="2020-08-24_00-13"></p>
<h3 id="7-生成等差数列的tensor"><a href="#7-生成等差数列的tensor" class="headerlink" title="7.生成等差数列的tensor"></a>7.生成等差数列的tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#相关函数说明</span></span><br><span class="line">torch.arange( start ,end , offset )</span><br><span class="line"><span class="comment">#torch.range(start,end, offset) #闭区间</span></span><br><span class="line">torch.linspace(start, end, steps=<span class="number">100</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Return </span></span><br><span class="line"><span class="string">start (float) – the starting value for the set of points</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">end (float) – the ending value for the set of points</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">steps (int) – number of points to sample between start and end. Default: 100.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">torch.logspace(torch.logspace(start, end, steps=<span class="number">100</span>, base=<span class="number">10.0</span>, out=<span class="literal">None</span>, dtype=<span class="literal">None</span>, layout=torch.strided, device=<span class="literal">None</span>, requires_grad=<span class="literal">False</span>) → Tensor</span><br><span class="line">               </span><br><span class="line"> <span class="string">&#x27;&#x27;&#x27;  </span></span><br><span class="line"><span class="string">    Returns a one-dimensional tensor of steps points logarithmically spaced with base base between base^&#123;start&#125;  and  base^&#123;end&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-24_00-14.png" alt="2020-08-24_00-14"></p>
<p>???=＝如何设置base==</p>
<h3 id="8-其他生成函数-Ones-zeros-eye"><a href="#8-其他生成函数-Ones-zeros-eye" class="headerlink" title="8.其他生成函数(Ones, zeros,eye)"></a>8.其他生成函数(Ones, zeros,eye)</h3><p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-24_00-23.png" alt="2020-08-24_00-23"></p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-24_00-23_1.png" alt="2020-08-24_00-23_1"></p>
<h3 id="9-randperm-random-shuffle"><a href="#9-randperm-random-shuffle" class="headerlink" title="9.randperm(random.shuffle)"></a>9.randperm(random.shuffle)</h3><p>??</p>
<p><img src="pytorch%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/2020-08-24_00-26.png" alt="2020-08-24_00-26"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/08/23/git%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/08/23/git%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">git命令</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-08-23 08:07:42" itemprop="dateCreated datePublished" datetime="2020-08-23T08:07:42+08:00">2020-08-23</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-24 08:46:08" itemprop="dateModified" datetime="2020-08-24T08:46:08+08:00">2020-08-24</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/git/" itemprop="url" rel="index"><span itemprop="name">git</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/git/%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/" itemprop="url" rel="index"><span itemprop="name">基本操作</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="git学习和博客搭建的相关资源"><a href="#git学习和博客搭建的相关资源" class="headerlink" title="git学习和博客搭建的相关资源"></a>git学习和博客搭建的相关资源</h2><h3 id="1-hexo搭建博客的相关参考博客"><a href="#1-hexo搭建博客的相关参考博客" class="headerlink" title="1. hexo搭建博客的相关参考博客"></a>1. hexo搭建博客的相关参考博客</h3><p>​    a.如何在本地库增加新的博客</p>
<p><a target="_blank" rel="noopener" href="https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/">https://winney07.github.io/2018/08/02/%E5%9C%A8Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0/</a></p>
<p> b.如何搭建博客</p>
<p>​    <a target="_blank" rel="noopener" href="http://www.wzqj.top/2019/02/26/linux%E4%B8%8B%E4%BD%BF%E7%94%A8-Github-Pages-Hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">http://www.wzqj.top/2019/02/26/linux%E4%B8%8B%E4%BD%BF%E7%94%A8-Github-Pages-Hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</a></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000017986794">https://segmentfault.com/a/1190000017986794</a></p>
<p>c.hexo的常见命令</p>
<p><a target="_blank" rel="noopener" href="https://vel.life/Hexo-%E5%8D%9A%E6%96%87%E7%BC%96%E8%BE%91%E6%89%8B%E5%86%8C/">https://vel.life/Hexo-%E5%8D%9A%E6%96%87%E7%BC%96%E8%BE%91%E6%89%8B%E5%86%8C/</a></p>
<p><strong>托管中心</strong><code>维护远程库</code></p>
<ul>
<li><strong>内网：可以自己搭建一个GitLab服务器</strong></li>
<li><strong>外网：可以使用码云、Github</strong></li>
</ul>
<p><strong>版本控制工具</strong></p>
<ul>
<li><strong>集中式</strong>：CSV ,<strong>SVN</strong>,VSS</li>
<li><strong>分布式</strong>：<strong>Git</strong>，Darcs,…</li>
</ul>
<h2 id="Git命令行操作"><a href="#Git命令行操作" class="headerlink" title="Git命令行操作"></a>Git命令行操作</h2><h3 id="1-1本地库初始化"><a href="#1-1本地库初始化" class="headerlink" title="1.1本地库初始化"></a>1.1本地库初始化</h3><p><code>进入文件夹</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">注意：生成的 .git 目录中存放的是本地库相关文件，不要删除</span><br></pre></td></tr></table></figure>

<h3 id="1-2设置签名"><a href="#1-2设置签名" class="headerlink" title="1.2设置签名"></a>1.2设置签名</h3><ul>
<li><p>项目(仓库)级别<code>仅在当前本地库有效</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config user.name tom  #设置用户名tom</span><br><span class="line">git config user.email liu@qq.com #设置用户邮箱</span><br></pre></td></tr></table></figure></li>
<li><p>系统用户级别<code>仅在当前登录的操作系统用户有效</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name tom</span><br><span class="line">git config --global user.email liu@qq.com</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>仅仅加了一个 <code>--global</code></p>
<p>优先级别：<code>项目级别</code>  &gt;  <code>系统级别</code></p>
<p>信息保存位置：<code>~/.gitconfig 文件</code>   </p>
</blockquote>
<h3 id="1-3基本操作"><a href="#1-3基本操作" class="headerlink" title="1.3基本操作"></a>1.3基本操作</h3><h4 id="1-3-1-状态查看"><a href="#1-3-1-状态查看" class="headerlink" title="1.3.1 状态查看"></a>1.3.1 状态查看</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git status   #查看工作区、暂存区状态</span><br></pre></td></tr></table></figure>

<h4 id="1-3-2-添加"><a href="#1-3-2-添加" class="headerlink" title="1.3.2 添加"></a>1.3.2 添加</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add fileName  #指定文件</span><br><span class="line">git add . #所有</span><br><span class="line">说明：将工作区的文件添加到暂存区</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git rm --cached filename</span><br><span class="line">git rm /*</span><br><span class="line">＃将filename对应的文件从缓存区撤回，但是文件仍保留在工作区，相当于是add的一个撤回操作　sudo权限</span><br></pre></td></tr></table></figure>



<h4 id="1-3-3-提交"><a href="#1-3-3-提交" class="headerlink" title="1.3.3 提交"></a>1.3.3 提交</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &#x27;commit message&#x27; fileName</span><br><span class="line">说明：将暂存区内容提交到本地库,不需要再通过vim编辑提交的说明信息，没有提交信息，本次提交将无效</span><br><span class="line">git commit *</span><br><span class="line">说明：将暂存区中的所有内容都提交到本地库中</span><br></pre></td></tr></table></figure>

<p>文件修改之后</p>
<ol>
<li>要先git add加到暂存区中，之后再添加到git commit</li>
<li>或者直接使用 git -a commit filename 这时本次提交不能撤回(git rm /*)</li>
</ol>
<h4 id="1-3-4-查看历史记录"><a href="#1-3-4-查看历史记录" class="headerlink" title="1.3.4 查看历史记录"></a>1.3.4 查看历史记录</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git log #查看提交的日志，包括时间，提交的说明信息</span><br><span class="line">git reflog  #常用</span><br><span class="line">git log --greph #图形显示,更直观</span><br><span class="line">git log --pretty=oneline #每行日志</span><br><span class="line">git log --oneline #简洁显示</span><br><span class="line">说明：HEAD@&#123;移动到当前版本需要多少步&#125;</span><br></pre></td></tr></table></figure>

<p><img src="git%E5%91%BD%E4%BB%A4/2020-08-23_10-49.png" alt="2020-08-23_10-49"></p>
<p>哈希值＋指针移动量＋提交的说明信息</p>
<p>多屏控制的方式：</p>
<p>１．空格向下翻页　，ｂ向下翻页　，ｑ退出</p>
<p><img src="git%E5%91%BD%E4%BB%A4/2020-08-23_10-59.png" alt="2020-08-23_10-59"></p>
<h4 id="1-3-5-前进后退"><a href="#1-3-5-前进后退" class="headerlink" title="1.3.5 前进后退"></a>1.3.5 前进后退</h4><ul>
<li><p>基于索引值<code>推荐</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard 指针位置</span><br><span class="line">例子：git reset --hard a6ace91 #回到这个状态，a6ace91指的是日志的短的索引值</span><br></pre></td></tr></table></figure></li>
<li><p>使用 <strong>^</strong> 符号<code>只能后退</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard HEAD^</span><br><span class="line">例子：git reset --hard HEAD^^</span><br><span class="line">注意：几个 ^ 表示后退几步</span><br></pre></td></tr></table></figure></li>
<li><p>使用 <strong>~</strong> 符号<code>只能后退</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard HEAD~n</span><br><span class="line">例子：git reset --hard HEAD~3</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="1-3-6-reset的三个参数比较"><a href="#1-3-6-reset的三个参数比较" class="headerlink" title="1.3.6 reset的三个参数比较"></a>1.3.6 reset的三个参数比较</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">soft: </span><br><span class="line">  - 仅本地库移动HEAD 指针</span><br><span class="line">mixed:</span><br><span class="line">  - 在本地库移动HEAD指针</span><br><span class="line">  - 重置暂存区</span><br><span class="line">hard:</span><br><span class="line">  - 在本地库移动HEAD指针</span><br><span class="line">  - 重置暂存区－－及暂存区的文件也回到之前的版本</span><br><span class="line">  - 重置工作区</span><br></pre></td></tr></table></figure>

<h4 id="1-3-7-删除文件并找回"><a href="#1-3-7-删除文件并找回" class="headerlink" title="1.3.7　删除文件并找回"></a>1.3.7　删除文件并找回</h4><ul>
<li><strong>相当于建立一个快照，虽然删除了，但只要添加到暂存区，就能找回</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard 指针位置</span><br></pre></td></tr></table></figure>

<p><img src="git%E5%91%BD%E4%BB%A4/2020-08-23_11-45.png" alt="2020-08-23_11-45"></p>
<h4 id="1-3-8-文件差异比较"><a href="#1-3-8-文件差异比较" class="headerlink" title="1.3.8 文件差异比较"></a>1.3.8 文件差异比较</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git diff 文件名 #将工作区中的文件与暂存区中的文件进行比较</span><br><span class="line">git diff 哈希值 文件名  #将工作区中的文件和历史中的一个版本比较</span><br><span class="line">git diff  #不带文件名，则比较多个文件</span><br></pre></td></tr></table></figure>

<h3 id="2-2-分支管理"><a href="#2-2-分支管理" class="headerlink" title="2.2 分支管理"></a>2.2 分支管理</h3><p><code>hot_fix</code> <code>master</code> <code>feature_x</code> <code>feature_y</code></p>
<h4 id="2-2-1-什么是分支管理"><a href="#2-2-1-什么是分支管理" class="headerlink" title="2.2.1 什么是分支管理"></a>2.2.1 什么是分支管理</h4><ul>
<li>在版本控制中，使用推进多个任务</li>
</ul>
<h4 id="2-2-2-分支的好处"><a href="#2-2-2-分支的好处" class="headerlink" title="2.2.2 分支的好处"></a>2.2.2 分支的好处</h4><ul>
<li>同时并行推进多个功能开发，提高开发效率</li>
<li>某一分支开发失败，不会对其它分支有任何影响</li>
</ul>
<h4 id="2-2-3-分支操作"><a href="#2-2-3-分支操作" class="headerlink" title="2.2.3 分支操作"></a>2.2.3 分支操作</h4><ul>
<li>创建分支</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch 分支名</span><br></pre></td></tr></table></figure>

<ul>
<li>查看分支</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br><span class="line">git branch -v </span><br></pre></td></tr></table></figure>

<ul>
<li>切换分支</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout 分支名</span><br><span class="line">git checkout -b 分支名   #创建分支并直接切换到该分支</span><br></pre></td></tr></table></figure>

<ul>
<li>合并分支<code>相当于把修改了的文件拉过来</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git merge xxx</span><br><span class="line">注意：合并分支的时候要明确谁谁合并</span><br><span class="line">	我在a分支里面修改了。要合并到master，就先切换到master，然后合并b</span><br></pre></td></tr></table></figure>

<ul>
<li>删除分支</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -d 分支名</span><br></pre></td></tr></table></figure>



<h4 id="2-2-4-解决冲突"><a href="#2-2-4-解决冲突" class="headerlink" title="2.2.4 解决冲突"></a>2.2.4 解决冲突</h4><ul>
<li>冲突的表现</li>
<li>冲突的解决<ul>
<li>第一步：编辑，删除特殊标记<code>&lt;&lt;&lt;</code> <code>===</code></li>
<li>第二步：修改到满意位置，保存退出</li>
<li>第三步：添加到缓存区  <code>git  add 文件名</code></li>
<li>第四步：提交到本地库<code>git commit -m &#39;日志信息&#39; </code>  <code>注意：后面一定不能带文件名</code></li>
</ul>
</li>
</ul>
<h2 id="Git-结合Github"><a href="#Git-结合Github" class="headerlink" title="Git 结合Github"></a>Git 结合Github</h2><p><code>别分手</code>  <code>别名 分支名</code></p>
<h4 id="1-1-创建远程库地址别名"><a href="#1-1-创建远程库地址别名" class="headerlink" title="1.1 创建远程库地址别名"></a>1.1 创建远程库地址别名</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git remote -v  #查看远程地址别名</span><br><span class="line">git remote add 别名 远程地址 </span><br><span class="line">例子：git remote add origin https://xx</span><br></pre></td></tr></table></figure>

<h4 id="1-2-推送"><a href="#1-2-推送" class="headerlink" title="1.2 推送"></a>1.2 推送</h4><p><code>开发修改完把本地库的文件推送到远程仓库</code> <code>前提是提交到了本地库才可以推送</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git push 远程库别名 分支名</span><br><span class="line">git push -u 远程库别名 分支名    #-u指定默认主机</span><br><span class="line">例子：git push origin master</span><br></pre></td></tr></table></figure>

<h4 id="1-3-克隆"><a href="#1-3-克隆" class="headerlink" title="1.3 克隆"></a>1.3 克隆</h4><p><code>完整的把远程库克隆到本地</code>  <code>克隆下来后不要在主分支里面做开发</code> <code>clone进行一次，从无到有的过程，更新用pull</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone  远程地址</span><br><span class="line">例子：git clone https://xx</span><br></pre></td></tr></table></figure>

<h4 id="1-4-拉取"><a href="#1-4-拉取" class="headerlink" title="1.4 拉取"></a>1.4 拉取</h4><p>  <code>本地存在clone下来的文件  就用pull更新</code>  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pull = fetch + merge</span><br><span class="line">	git fetch 别名 分支名</span><br><span class="line">	git merge 别名 分支名</span><br><span class="line">git pull 别名 分支名</span><br></pre></td></tr></table></figure>

<h4 id="1-5-解决冲突"><a href="#1-5-解决冲突" class="headerlink" title="1.5 解决冲突"></a>1.5 解决冲突</h4><p><code>注意：解决冲突后的提交是不能带文件名的</code></p>
<p><code>如果不是基于远程库最新版做的修改不能推送，必须先pull下来安装冲突办法解决</code></p>
<h4 id="1-6-rebase"><a href="#1-6-rebase" class="headerlink" title="1.6 rebase"></a>1.6 rebase</h4><p><code>提交记录简洁不分叉</code>  <code>没学懂，感觉有点鸡肋</code> <code>混眼熟</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git rebase -i 索引号</span><br><span class="line">git rebase -i HEAD~3  #合并最近三条记录</span><br><span class="line">说明：在vim编辑里面改成s</span><br></pre></td></tr></table></figure>

<h4 id="1-7-beyond-compare"><a href="#1-7-beyond-compare" class="headerlink" title="1.7 beyond compare"></a>1.7 beyond compare</h4><p><code>用软件解决冲突</code> </p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.安装 ：</span><br><span class="line">	beyond compare </span><br><span class="line">2.配置：</span><br><span class="line">    git config --local merge.tool bc3  #合并名称</span><br><span class="line">    git config --local mergetool.path &#x27;/usr/local/bin/bcomp&#x27; #软件路径</span><br><span class="line">    git config --local mergetool.keepBackup false  #False不用保存备份</span><br><span class="line">3.应用：</span><br><span class="line">	git mergetool</span><br><span class="line">说明：--local指只在当前操作系统有效</span><br></pre></td></tr></table></figure>

<h4 id="1-8-跨团队合作"><a href="#1-8-跨团队合作" class="headerlink" title="1.8 跨团队合作"></a>1.8 跨团队合作</h4><p><code>代码review之后合并</code></p>
<ul>
<li><p><strong>适用于个人</strong></p>
<p><strong>邀请成员</strong>:<code>Settings</code> –&gt; <code>Collaborators</code> –&gt;<code>填写用户名</code> –&gt;<code>打开链接接受邀请</code></p>
</li>
<li><p><strong>企业</strong>   <code>创建一个组织</code> <code>方便管理</code></p>
</li>
<li><p><strong>review</strong></p>
<p><code>组织做review</code>  <code>通过Pull request</code></p>
</li>
<li><p><strong>给开源社区共享代码</strong></p>
<p><code>点击别人仓库的fork 到自己的仓库</code>   – &gt; <code>然后clone下来 修改后推送到远程库</code>  –&gt; <code>点击Pull Request请求</code> –&gt; <code>Create pull request发消息</code></p>
</li>
</ul>
<h4 id="1-9-Tag标签"><a href="#1-9-Tag标签" class="headerlink" title="1.9 Tag标签"></a>1.9 Tag标签</h4><p><code>为了清晰的版本管理，公司一般不会直接使用commit提交</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git tag -a v1.0 -m &#x27;版本介绍&#x27;   #创建本地tag信息</span><br><span class="line">git tag -d v1.0    		#删除tag</span><br><span class="line">git push origin --tags   #将本地tag信息推送到远程库</span><br><span class="line">git pull origin --tags    #拉取到本地</span><br><span class="line"></span><br><span class="line">git checkout v.10    #切换tag</span><br><span class="line">git clone -b v0.1 地址   #指定tag下载代码</span><br></pre></td></tr></table></figure>



<h4 id="1-10-SSH-免密登录"><a href="#1-10-SSH-免密登录" class="headerlink" title="1.10 SSH 免密登录"></a>1.10 SSH 免密登录</h4><ul>
<li>输入:<code>ssh-keygen -t rsa -C GitHub邮箱地址</code>  </li>
<li>进入<code>.ssh</code>目录，复制<code>id_rsa.pub</code>文件内容</li>
<li>登录GitHub。<code>Settings</code>  –&gt; <code>SSH and GPG keys </code> –&gt; <code>New SSH Key    </code></li>
<li>回到git通过ssh地址创建。<code>git remote add 别名 SSH地址  </code></li>
</ul>
<h2 id="Git工作流"><a href="#Git工作流" class="headerlink" title="Git工作流"></a>Git工作流</h2><h4 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a>1.1 概念</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在项目开发过程中使用Git的方式</span><br></pre></td></tr></table></figure>

<h4 id="1-2-分类"><a href="#1-2-分类" class="headerlink" title="1.2 分类"></a>1.2 分类</h4><h5 id="1-2-1-集中式工作流"><a href="#1-2-1-集中式工作流" class="headerlink" title="1.2.1 集中式工作流"></a>1.2.1 集中式工作流</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">像SVN一样，集中式工作流有一个中央仓库，所有的修改都提交到了Master分支上</span><br></pre></td></tr></table></figure>

<h5 id="1-2-2-GitFlow工作流"><a href="#1-2-2-GitFlow工作流" class="headerlink" title="1.2.2 GitFlow工作流 *"></a>1.2.2 GitFlow工作流 <code>*</code></h5><p>主干分支<code>master</code>  开发分支<code>develop</code>  修复分支<code>hotfix</code>   预发布分支<code>release</code>  功能分支<code>feature</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GitFlow 有独立的分支，让发布迭代过程更流畅。</span><br></pre></td></tr></table></figure>

<h5 id="1-2-3-Forking-工作流"><a href="#1-2-3-Forking-工作流" class="headerlink" title="1.2.3 Forking 工作流"></a>1.2.3 Forking 工作流</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在 GitFlow 基础上， 充分利用了 Git 的 Fork 和 pull request 的功能以达到代码审核的目的。 </span><br><span class="line">安全可靠地管理大团队的开发者</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/02/article1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/aa.webp">
      <meta itemprop="name" content="Sherry Wang">
      <meta itemprop="description" content="记录点滴成长">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Think World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/06/02/article1/" class="post-title-link" itemprop="url">article1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Veröffentlicht am</span>

      <time title="Erstellt: 2020-06-02 08:20:26" itemprop="dateCreated datePublished" datetime="2020-06-02T08:20:26+08:00">2020-06-02</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Bearbeitet am</span>
        <time title="Geändert am: 2020-08-27 07:38:08" itemprop="dateModified" datetime="2020-08-27T07:38:08+08:00">2020-08-27</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">in</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
        </span>
          . 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94/%E7%94%9F%E7%89%A9%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">生物医学大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="实验背景"><a href="#实验背景" class="headerlink" title="实验背景"></a>实验背景</h2><pre><code>             DNA甲基化（DNAm）是在核苷酸（通常是胞嘧啶）上添加一个甲基，该核苷酸不会改变DNA序列，并且最常见于胞嘧啶-鸟嘌呤二核苷酸（CpG）。DNA的甲基化区域（高甲基化）与浓缩的染色质相关，当存在于基因启动子附近时，会抑制转录。DNA的未甲基化区域（低甲基化）与开放的染色质状态相关，并允许基因转录。DNAM模式与细胞类型特异性基因表达程序相关联，和改变DNAM已经与衰老和环境暴露有关[ [8](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#CR8)，[9](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#CR9)]。此外，众所周知，DNAm的改变有助于癌症的发展和发展。抑癌基因的甲基化过高和癌基因的甲基化过低会导致发病机制和不良预后。抑癌基因的甲基化过高和癌基因的甲基化过低会导致发病机制和不良预后。 基于负担得起的基于阵列的基因组规模测量DNAm的方法已经增强了表观基因组广泛关联研究（EWAS），用于测试DNAm与表型，暴露水平以及人类健康和疾病状态的关联。 因为DNAm模式是特定于细胞类型的，所以EWAS通常使用基于参考或无参考的方法推断生物样品细胞组成变化所引起的潜在混淆，以推断细胞类型的比例
</code></pre>
<h2 id="KeyWords"><a href="#KeyWords" class="headerlink" title="KeyWords:"></a>KeyWords:</h2><h2 id="相关统计概念"><a href="#相关统计概念" class="headerlink" title="相关统计概念:"></a>相关统计概念:</h2><p>Shapley value : 基于Shapley值进行利益分配体现了各盟员对联盟总目标的贡献程度,避免了分配的平均主义,比任何一种仅按资源投入价值、资源配置效率及将二者相结合的分配方式都更具合理性和公平性，也体现了各盟员相互博弈的过程。但Shapley值法的利益分配方案尚未考虑联盟成员的风险分担因素，实质上隐含着各盟员风险分担均等的假设，因此，对于联盟成员风险分担不等或风险分担存在较大差异的状况，需要根据风险分担大小对Shapley值法的利益分配方案做出适当的修正</p>
<p><a target="_blank" rel="noopener" href="https://wiki.mbalib.com/wiki/%E5%A4%8F%E6%99%AE%E5%88%A9%E5%80%BC">https://wiki.mbalib.com/wiki/%E5%A4%8F%E6%99%AE%E5%88%A9%E5%80%BC</a></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Shapley_value">https://en.wikipedia.org/wiki/Shapley_value</a></p>
<h2 id="相关生物背景知识"><a href="#相关生物背景知识" class="headerlink" title="相关生物背景知识:"></a>相关生物背景知识:</h2><p>CpGs :        <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/CpG_site">https://en.wikipedia.org/wiki/CpG_site</a></p>
<p>在哺乳动物中，70％至80％的CpG胞嘧啶被甲基化。[<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/CpG_site#cite_note-Jabbari2004-1">1]</a>对基因内的胞嘧啶进行甲基化可以改变其表达</p>
<h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><h3 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h3><h4 id="主要分为3部分"><a href="#主要分为3部分" class="headerlink" title="主要分为3部分"></a>主要分为3部分</h4><p>​    我们的方法使用一些简单的命令，所有这些命令都可以用于任何预测任务。首先，使用变分自动编码器对深度学习预测模型进行预训练，然后使用编码器的层提取生物学上有意义的特征。这些神经网络层用于嵌入数据并提取特征，以便在无监督的情况下进行聚类，生成对原始源具有高保真度的新数据以及进行预测模型预训练。其次，在编码器的下游包括预测层，它们可以端对端地微调模型的预测层和特征提取层，以实现多输出回归和分类的任务。训练预测层可优化神经网络以执行预测任务。第三，进行自主超参数扫描以优化第一和第二任务的模型参数，同时生成丰富的数据可视化。最后，通过Shapley特征归因方法确定CpG对每个预测的不同粒度程度的贡献。</p>
<p>预训练 Training the feature extractor to embed data</p>
<p> emded data嵌入数据的程序是通过使用VAE(Variational Autoencoder )来找到无监督潜在的数据的表征(representation)去预训练最后的预测模型</p>
<p>​    其中VAE主要有两部分:编码器和解码器:</p>
<p>​            1. 编码器主要用于 压缩数据,然后将此压缩得到的representations,这些压缩数据作为解码器的输入,</p>
<pre><code>               2. 解码器尝试进行重建原始数据集,同时尝试生成合成样本(synthetic training examples),并且在这两者之间进行权衡.
                                      1. synthetic training examples: 对于在训练用于预测任务的网络时增加噪声很重要,该组件作为正则化形式的一部分,提高算法的在测试数据上的准确性和泛化能力
                                      2. 原始数据也很重要,它是真实正确的样本,决定数据的潜在表示如何捕获正确描述基础信息的特征,保证了算法的正确性
</code></pre>
<p>  <img src="article1/1.jpg" alt="1"></p>
<h3 id="相关数据集"><a href="#相关数据集" class="headerlink" title="相关数据集"></a>相关数据集</h3><p>数据集1: 用于研究年龄和细胞类型分类,该数据集是是年龄范围广的健康受试者最大的现成的最大DNAm数据集之一（GSE87571为15至95岁的人的血液<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE87571">DNAm</a> [ <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#CR28">28</a> ]；补充图<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#MOESM1">1</a>和补充表 <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#MOESM1">1</a>）</p>
<p>第二数据集（癌症基因组图谱，TCGA）用于研究癌症亚型和包括表示32个不同的癌症亚型（补充表格8376个样品 <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#MOESM1">1</a>，<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#MOESM1">2</a>）。</p>
<p>第三个数据集（Liu数据集）用于比较类风湿性关节炎研究（<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42861">GSE42861</a>，子集<em>n</em> = 188 [ <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7076991/#CR29">29</a> ]）中当前吸烟者和从未吸烟者的血液DNAm 。[整个表观基因组关联数据表明.DNA甲基化是类风湿关节炎遗传风险的中介]</p>
<p>这三个数据集使用<em>PyMethylProcess</em>进行了预处理，分别产生300 k，200 k和300 k CpG特征，然后分为70％训练，20％测试和10％验证。</p>
<p>三个额外的数据集（<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE40279">GSE40279</a>，<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE84207">GSE84207</a>和<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE75067">GSE75067</a>）用于外部验证和乳腺肿瘤亚型的初步评估。</p>
<h3 id="DNAm-encoding的动机"><a href="#DNAm-encoding的动机" class="headerlink" title="DNAm encoding的动机"></a>DNAm encoding的动机</h3><p>建立了甲基化网络作为DNAm编码的一种方法，证明能够再现原始DNAm信号，同时提供优越的聚类性能超过最先进的聚类方法，如递归分区混合建模(RPMM)<a href="%E5%8F%82%E8%A7%81%E8%A1%A5%E5%85%85%E6%9D%90%E6%96%99%EF%BC%8C%22%E6%97%A0%E7%9B%91%E7%9D%A3%E7%BC%96%E7%A0%81%E5%99%A8%E6%80%A7%E8%83%BD%E7%9A%84%E8%AF%84%E4%BC%B0%22;%E8%A1%A5%E5%85%85%E5%9B%BE2%E3%80%813%E5%92%8C4">30</a>考虑到甲基网络在非监督域的表现以及它对DNAm f进行有意义编码的能力,我们选择进行DNAm encoding</p>
<p>实验1:</p>
<h3 id="VAE-variational-Auto-Encoder"><a href="#VAE-variational-Auto-Encoder" class="headerlink" title="VAE :variational Auto-Encoder"></a>VAE :variational Auto-Encoder</h3><p>在MethyNet中的功能是 extract biologically meaningful features and  downstream prediction tasks</p>
<p>由两部分构成encoder 和 decoder</p>
<p>迁移学习的介绍:<a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2018-01-04-7">https://www.jiqizhixin.com/articles/2018-01-04-7</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left" aria-label="Vorherige Seite"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right" aria-label="Nächste Seite"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sherry Wang</span>
</div>
  <div class="powered-by">Erstellt mit  <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  





</body>
</html>
